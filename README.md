# Webscraper

Ohh ja natuurlijk, wel even wat instructies voor de echte leken onder ons:
Als je Python en alles hebt ge√Ønstalleerd, dan kan je het programmaatje starten en dan krijg je een venstertje te zien. 
- Je voert daar een URL in zoals https://www.startpagina.nl. 
- Je klikt eenmaal op redirect console to widget
- En je klikt op Run crawl 
En dan gaat ie dan alle linkjes van de website af halen die van belang zijn, en geeft ze weer op het scherm. Aan het einde schrijft hij ook de unieke linkjes weg in een textbestand in dezelfde map als het programma.
 
 Dit is een poging tot een webscraper.

 Dit is op zich een interessant project om als beginner op te pakken. Het is een bot die over het internet surft en bepaalde data voor je automatisch verzameld.

 Dat kan inhouden dat je slechts links verzameld naar verder gelinkte websites. Denk aan te beginnen op startpagina en daar alle links af te gaan om te kijken wat voor een websites je allemaal gevonden kunt krijgen.

 Op een gegeven moment wilde ik dit programma ook een UI geven. Ik kreeg het echter niet meteen voor elkaar om een steady stream met URL's weer te geven in het programma, zoals de console dat doet tijdens het debuggen.

 Dit heb ik echter met AI samen uitgepluisd. En het is in orde zo.

 Het programma doet precies wat ik wil. En output hem in een text file. Alleen die text file is niet zichtbaar voor git. En is ook niet nodig. Als je het resultaat wil van de crawl, fork dit dan zelf en run hem dan op je computer.

 Misschien verbeter ik hem zelfs nog verder. Maar het doel was om er een afgerond geheel van te maken. En dat is het nu in feite al, vind ik.